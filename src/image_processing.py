#This module has image resizing and normalization related content...

from __future__ import annotations
from pathlib import Path
from typing import Iterable, List, Dict
from PIL import Image, UnidentifiedImageError
import pandas as pd
import torch
from torchvision import transforms
# import torch.nn.functional as F
from torchvision.models import resnet50, ResNet50_Weights
import torch.nn as nn


def load_image(path: Path) -> Image.Image:
    try:
        with Image.open(path) as im:
            return im.copy()
    except FileNotFoundError:
        raise
    except UnidentifiedImageError as e:
        raise RuntimeError(f"Unreadable/corrupt image: {path}") from e

def build_transform(img_size: int):
    return transforms.Compose([
        transforms.Resize(int(img_size * 1.15)),
        transforms.CenterCrop(img_size),
        transforms.ToTensor(),
        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
    ])

def process_image_file(
    src_path: Path,
    dest_root: Path,
    img_size: int = 224,
    keep_name: bool = False,
    save_png: bool = False
) -> Dict:
    """
    Process a single image: load, transform to tensor (normalized for ResNet),
    and optionally save a PNG for visualization.
    Returns metadata including the tensor and saved path (if applicable).
    """
    meta = {
        "source_path": str(src_path),
        "status": "ok",
        "tensor": None,
        "saved_path": None,
    }

    try:
        img = load_image(src_path)
    except FileNotFoundError:
        meta["status"] = "missing"
        return meta
    except RuntimeError:
        meta["status"] = "corrupt"
        return meta

    # Apply transform
    transform = build_transform(img_size)
    img_tensor = transform(img)
    meta["tensor"] = img_tensor

    if save_png:
        # Save a visualizable PNG version
        dest_root.mkdir(parents=True, exist_ok=True)
        out_name = f"{src_path.stem}.png" if keep_name else f"{src_path.stem.replace(' ', '_').lower()}.png"
        out_path = dest_root / out_name

        # Use a transform that only resizes + center crops (no normalization) for visualization
        vis_transform = transforms.Compose([
            transforms.Resize(int(img_size * 1.15)),
            transforms.CenterCrop(img_size),
        ])
        vis_img = vis_transform(img)
        vis_img.save(out_path, format="PNG", optimize=True)
        meta["saved_path"] = str(out_path)

    return meta

#Batch Processing the images...
def batch_process_images(image_names: Iterable[str],
                         src_dir: Path,
                         dest_dir: Path,
                         img_size: int = 224,
                         keep_name: bool = False,
                         save_png: bool = True) -> pd.DataFrame:

    rows: List[Dict] = []
    for name in image_names:
        meta = process_image_file(Path(src_dir) / name,
                                  Path(dest_dir),
                                  img_size=img_size,
                                  keep_name=keep_name,
                                  save_png=save_png)
        meta["image_name"] = name
        meta["image_id"] = Path(meta["saved_path"]).stem if meta["saved_path"] else Path(name).stem
        rows.append(meta)
    return pd.DataFrame(rows)


def load_resnet_encoder(device="cpu"):
    weights = ResNet50_Weights.DEFAULT
    model = resnet50(weights=weights)

    # Remove the final classification layer
    encoder = nn.Sequential(*list(model.children())[:-1])  
    # Now encoder outputs: [batch, 2048, 1, 1]

    encoder.to(device)
    encoder.eval()
    return encoder

def encode_image(tensor, encoder, device="cpu"):
    tensor = tensor.unsqueeze(0).to(device)
    with torch.no_grad():
        features = encoder(tensor)      # shape [1, 2048, 1, 1]
        features = features.flatten(1)  # shape [1, 2048]
    return features.squeeze(0).cpu()    # shape [2048]

# src_path = Path("raw/Set1/images/File_name_2022-09-12T10_22_29.720753.jpg")
#
# # Where to save optional PNG visualizations (optional)
# dest_root = Path("processed/Set1/")
#
# meta = process_image_file(
#     src_path=src_path,
#     dest_root=dest_root,
#     img_size=224,
#     keep_name=False,
#     save_png=True       # set to False if you don't want PNGs
# )
#
# # Check if the image was loaded successfully
# if meta["status"] != "ok":
#     print("Image could not be processed:", meta["status"])
# else:
#     print("Image processed!")
#
#     # 2. Load the ResNet feature extractor
#     device = "cpu"      # or "cuda" if you have a GPU
#     encoder = load_resnet_encoder(device=device)
#
#     # 3. Get the embedding (2048-dimensional tensor)
#     embedding = encode_image(meta["tensor"], encoder, device=device)
#
#     print("Embedding shape:", embedding.shape)
#     print("First 10 embedding values:", embedding[:10])