{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c579a90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#  COMPLETE SCRIPT — 3 INDEPENDENT WEAR REGRESSION NETWORKS\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "#  Dataset\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "class WearPairDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each sample:\n",
    "      ref_img, curr_img, w_ref[3], w_curr[3]  \n",
    "    \"\"\"\n",
    "    ## w_ref and w_curr are 3D y-wear vectors! The 3 wear types values of an image.\n",
    "    ## ref is the first image! All of these values are in a tuple in samples\n",
    "    def __init__(self, samples, transform):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ref_path, curr_path, w_ref, w_curr = self.samples[idx]\n",
    "\n",
    "        ref_img = self.transform(Image.open(ref_path).convert(\"RGB\"))\n",
    "        curr_img = self.transform(Image.open(curr_path).convert(\"RGB\"))\n",
    "\n",
    "        return (\n",
    "            ref_img,\n",
    "            curr_img,\n",
    "            torch.tensor(w_ref, dtype=torch.float32),\n",
    "            torch.tensor(w_curr, dtype=torch.float32),\n",
    "        )   ## This is just to retrieve the images and the wear values\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "#  Model\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "class WearNet(nn.Module):\n",
    "    def __init__(self, embed_dim=128, freeze_backbone=True):\n",
    "        super().__init__()\n",
    "\n",
    "        backbone = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        feat_dim = backbone.fc.in_features\n",
    "        backbone.fc = nn.Identity()\n",
    "\n",
    "        if freeze_backbone:\n",
    "            for p in backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        self.backbone = backbone\n",
    "        self.embedding = nn.Linear(feat_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)        # [B, 2048]\n",
    "        embed = self.embedding(feat)   # [B, D]\n",
    "        return embed\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "#  Loss\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "class WearDistanceLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    ||E_curr - E_ref|| ≈ |w_curr - w_ref|\n",
    "    \"\"\"\n",
    "    def forward(self, E_ref, E_curr, w_ref, w_curr):\n",
    "        d_embed = torch.norm(E_curr - E_ref, dim=1)\n",
    "        d_wear = torch.abs(w_curr - w_ref)\n",
    "        return ((d_embed - d_wear) ** 2).mean()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "#  Setup\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=(0.485, 0.456, 0.406),\n",
    "        std=(0.229, 0.224, 0.225),\n",
    "    ),\n",
    "])\n",
    "\n",
    "# samples = [\n",
    "#   (ref_img_path, curr_img_path, [w1,w2,w3], [w1,w2,w3]),\n",
    "#   ...\n",
    "# ]\n",
    "samples = []  # <-- fill this\n",
    "\n",
    "dataset = WearPairDataset(samples, transform)\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True) ## we are doing mini-batch training. U can also experiment by setting it to 1 or 8!!!\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "#  Three independent networks\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "nets = [WearNet(embed_dim=128, freeze_backbone=True).to(device) for _ in range(3)]\n",
    "optimizers = [\n",
    "    torch.optim.Adam(net.embedding.parameters(), lr=1e-3)\n",
    "    for net in nets\n",
    "]\n",
    "\n",
    "criterion = WearDistanceLoss()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "#  Training Loop\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = [0.0, 0.0, 0.0]\n",
    "\n",
    "    for ref_img, curr_img, w_ref, w_curr in loader:\n",
    "        ref_img = ref_img.to(device)\n",
    "        curr_img = curr_img.to(device)\n",
    "        w_ref = w_ref.to(device)    # [B, 3]\n",
    "        w_curr = w_curr.to(device)\n",
    "\n",
    "        for k in range(3):\n",
    "            net = nets[k]\n",
    "            opt = optimizers[k]\n",
    "\n",
    "            E_ref = net(ref_img)\n",
    "            E_curr = net(curr_img)\n",
    "\n",
    "            loss = criterion(\n",
    "                E_ref,\n",
    "                E_curr,\n",
    "                w_ref[:, k],\n",
    "                w_curr[:, k],\n",
    "            )   # The resnet backbone is frozen, what we train is the final head! For that we \n",
    "                # are using small batch training and our custom loss.\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_loss[k] += loss.item()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch} | \"\n",
    "        f\"Loss1: {total_loss[0]/len(loader):.4f} | \"\n",
    "        f\"Loss2: {total_loss[1]/len(loader):.4f} | \"\n",
    "        f\"Loss3: {total_loss[2]/len(loader):.4f}\"\n",
    "    )\n",
    "\n",
    "# ============================================================\n",
    "#  END\n",
    "# ============================================================\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
